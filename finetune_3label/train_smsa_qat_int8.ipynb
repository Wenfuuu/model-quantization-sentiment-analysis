{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47db3352",
   "metadata": {},
   "source": [
    "# IndoBERT QAT (Quantization-Aware Training) Pipeline - 3-Label Classification\n",
    "\n",
    "This notebook fine-tunes IndoBERT with Quantization-Aware Training (QAT) for INT8 quantization on 3-label sentiment analysis.\n",
    "\n",
    "**QAT vs PTQ:**\n",
    "- QAT: Quantization simulation during training (better accuracy)\n",
    "- PTQ: Quantization applied after training (faster, simpler)\n",
    "\n",
    "**Dataset:**\n",
    "SMSA (Sentiment Analysis) from IndoNLU benchmark\n",
    "\n",
    "**Labels:**\n",
    "- Positive (0)\n",
    "- Neutral (1)\n",
    "- Negative (2)\n",
    "\n",
    "**Pipeline:**\n",
    "1. Load SMSA dataset (train/val/test TSV files)\n",
    "2. Map text labels to numeric values\n",
    "3. Load FP32 model and prepare for QAT\n",
    "4. Fine-tune with fake quantization (INT8 simulation)\n",
    "5. Convert to actual INT8\n",
    "6. Evaluate quantized model\n",
    "\n",
    "**Hyperparameters:**\n",
    "- Learning rate: 2e-5\n",
    "- Batch size: 16\n",
    "- Epochs: 3\n",
    "- Quantization: INT8 (simulated during training)\n",
    "- Optimizer: AdamW\n",
    "- Max sequence length: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c862b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install transformers datasets accelerate\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "379e88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from collections import Counter\n",
    "from torch.ao.quantization import QConfig\n",
    "from torch.ao.quantization.observer import MovingAverageMinMaxObserver, MinMaxObserver\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.quantization as quantization\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a6093",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af17369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bertr\\anaconda3\\envs\\speech_recognition\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: BertTokenizerFast\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p2\")\n",
    "print(f\"Tokenizer loaded: {tokenizer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c82541",
   "metadata": {},
   "source": [
    "## Define Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f1eafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234416e",
   "metadata": {},
   "source": [
    "## Load SMSA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "452f8272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 11,000\n",
      "Validation samples: 1,260\n",
      "Test samples: 500\n",
      "\n",
      "Columns: ['text', 'label']\n",
      "\n",
      "Sample: {'text': 'warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !', 'label': 'positive'}\n",
      "\n",
      "Label distribution in training set:\n",
      "  positive: 6416\n",
      "  neutral: 1148\n",
      "  negative: 3436\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files={\n",
    "        'train': 'train.tsv',\n",
    "        'validation': 'valid.tsv',\n",
    "        'test': 'test.tsv'\n",
    "    },\n",
    "    delimiter='\\t',\n",
    "    column_names=['text', 'label']\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(dataset['train']):,}\")\n",
    "print(f\"Validation samples: {len(dataset['validation']):,}\")\n",
    "print(f\"Test samples: {len(dataset['test']):,}\")\n",
    "print(f\"\\nColumns: {dataset['train'].column_names}\")\n",
    "print(f\"\\nSample: {dataset['train'][0]}\")\n",
    "print(f\"\\nLabel distribution in training set:\")\n",
    "\n",
    "label_counts = Counter(dataset['train']['label'])\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"  {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a02db",
   "metadata": {},
   "source": [
    "## Map Labels to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b3716c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping:\n",
      "  positive -> 0\n",
      "  neutral -> 1\n",
      "  negative -> 2\n",
      "\n",
      "After mapping, sample label: 0\n",
      "Label type: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# label mapping\n",
    "label2id = {\n",
    "    'positive': 0,\n",
    "    'neutral': 1,\n",
    "    'negative': 2\n",
    "}\n",
    "id2label = {\n",
    "    0: 'positive',\n",
    "    1: 'neutral',\n",
    "    2: 'negative'\n",
    "}\n",
    "\n",
    "print(\"Label mapping:\")\n",
    "for label, idx in label2id.items():\n",
    "    print(f\"  {label} -> {idx}\")\n",
    "\n",
    "def map_labels(df):\n",
    "    df['label'] = [label2id[label] for label in df['label']]\n",
    "    return df\n",
    "\n",
    "dataset = dataset.map(\n",
    "    map_labels,\n",
    "    batched=True,\n",
    "    desc=\"Mapping labels to numeric values\"\n",
    ")\n",
    "\n",
    "print(\"\\nAfter mapping, sample label:\", dataset['train'][0]['label'])\n",
    "print(f\"Label type: {type(dataset['train'][0]['label'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a5525",
   "metadata": {},
   "source": [
    "## Load FP32 Model and Prepare for QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6b73954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 Model loaded: BertForSequenceClassification\n",
      "Number of parameters: 124,443,651\n",
      "Number of labels: 3\n",
      "Label mapping: {'positive': 0, 'neutral': 1, 'negative': 2}\n",
      "Skipping quantization for: word_embeddings (Embedding)\n",
      "Skipping quantization for: position_embeddings (Embedding)\n",
      "Skipping quantization for: token_type_embeddings (Embedding)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "Skipping quantization for: LayerNorm (LayerNorm)\n",
      "\n",
      "Model prepared for QAT\n",
      "Fake quantization modules inserted\n",
      "Model will simulate INT8 quantization during training\n"
     ]
    }
   ],
   "source": [
    "model_fp32 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"indobenchmark/indobert-base-p2\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "print(f\"FP32 Model loaded: {model_fp32.__class__.__name__}\")\n",
    "print(f\"Number of parameters: {model_fp32.num_parameters():,}\")\n",
    "print(f\"Number of labels: {model_fp32.config.num_labels}\")\n",
    "print(f\"Label mapping: {model_fp32.config.label2id}\")\n",
    "\n",
    "# switch model to training from eval mode to apply QAT\n",
    "model_fp32.train()\n",
    "\n",
    "# Create custom QConfig with per-tensor quantization\n",
    "qat_qconfig = QConfig(\n",
    "    activation=MovingAverageMinMaxObserver.with_args(\n",
    "        dtype=torch.quint8,\n",
    "        qscheme=torch.per_tensor_affine  # Use per-tensor instead of per-channel\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        qscheme=torch.per_tensor_symmetric  # Use per-tensor symmetric\n",
    "    )\n",
    ")\n",
    "\n",
    "# Apply config to model\n",
    "model_fp32.qconfig = qat_qconfig\n",
    "\n",
    "# Skip quantization for embedding and LayerNorm layers\n",
    "def set_qconfig_for_layers(module, qconfig):\n",
    "    \"\"\"Set qconfig for appropriate layers only\"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, (torch.nn.Embedding, torch.nn.LayerNorm)):\n",
    "            child.qconfig = None\n",
    "            print(f\"Skipping quantization for: {name} ({child.__class__.__name__})\")\n",
    "        else:\n",
    "            child.qconfig = qconfig\n",
    "            set_qconfig_for_layers(child, qconfig)\n",
    "\n",
    "set_qconfig_for_layers(model_fp32, qat_qconfig)\n",
    "\n",
    "# prepare model for QAT (inserts fake quantization modules)\n",
    "model_qat = quantization.prepare_qat(model_fp32, inplace=False)\n",
    "\n",
    "print(f\"\\nModel prepared for QAT\")\n",
    "print(f\"Fake quantization modules inserted\")\n",
    "print(f\"Model will simulate INT8 quantization during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d681a",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee9e2bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 126 Indonesian stop words\n",
      "Sample stop words: ['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua']\n"
     ]
    }
   ],
   "source": [
    "stopword_factory = StopWordRemoverFactory()\n",
    "indonesian_stopwords = stopword_factory.get_stop_words()\n",
    "\n",
    "print(f\"Loaded {len(indonesian_stopwords)} Indonesian stop words\")\n",
    "print(f\"Sample stop words: {list(indonesian_stopwords)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5311c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Ini adalah contoh kalimat! Apakah preprocessing berfungsi? 123 #test\n",
      "Preprocessed: contoh kalimat preprocessing berfungsi test\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove non-alphabetic characters (keep only letters and spaces)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # remove stop words\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in indonesian_stopwords]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "sample_text = \"Ini adalah contoh kalimat! Apakah preprocessing berfungsi? 123 #test\"\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Preprocessed: {preprocess_text(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8cdd3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing to dataset...\n",
      "Before preprocessing:\n",
      "  Sample text: warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih ...\n",
      "\n",
      "After preprocessing:\n",
      "  Sample text: warung dimiliki pengusaha pabrik tahu puluhan tahun terkenal membuat tahu putih bandung tahu berkual...\n",
      "\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying preprocessing to dataset...\")\n",
    "print(\"Before preprocessing:\")\n",
    "print(f\"  Sample text: {dataset['train'][0]['text'][:100]}...\")\n",
    "\n",
    "def preprocess_dataset(examples):\n",
    "    \"\"\"Apply preprocessing to a batch of examples\"\"\"\n",
    "    examples['text'] = [preprocess_text(text) for text in examples['text']]\n",
    "    return examples\n",
    "\n",
    "dataset = dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    desc=\"Preprocessing text\"\n",
    ")\n",
    "\n",
    "print(\"\\nAfter preprocessing:\")\n",
    "print(f\"  Sample text: {dataset['train'][0]['text'][:100]}...\")\n",
    "print(\"\\nPreprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7371ef7",
   "metadata": {},
   "source": [
    "## Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db8d1001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ab75e357624adcb6ae40751863b486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319aeb7a72c94ebab4d4d39bfc403dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b226c92a9f48038763e62eb315f9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete!\n",
      "Columns after tokenization: ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
      "\n",
      "Sample tokenized data:\n",
      "  input_ids length: 128\n",
      "  attention_mask length: 128\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    remove_columns=['text']\n",
    ")\n",
    "\n",
    "print(\"Tokenization complete!\")\n",
    "print(f\"Columns after tokenization: {tokenized_dataset['train'].column_names}\")\n",
    "print(f\"\\nSample tokenized data:\")\n",
    "print(f\"  input_ids length: {len(tokenized_dataset['train'][0]['input_ids'])}\")\n",
    "print(f\"  attention_mask length: {len(tokenized_dataset['train'][0]['attention_mask'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6c085",
   "metadata": {},
   "source": [
    "## Define Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad1d106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a98761",
   "metadata": {},
   "source": [
    "## Configure QAT Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT Training arguments configured:\n",
      "  Output directory: ./results/indobert-smsa-qat-int8\n",
      "  Learning rate: 2e-05\n",
      "  Batch size: 16\n",
      "  Epochs: 3\n",
      "  Quantization: INT8 (fake quant during training)\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./results/indobert-smsa-qat-int8\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    "    fp16=False,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "print(\"QAT Training arguments configured:\")\n",
    "print(f\"  Output directory: {output_dir}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Quantization: INT8 (fake quant during training)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db5ce4c",
   "metadata": {},
   "source": [
    "## Initialize Trainer for QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5924f53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT Trainer initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_qat,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(\"QAT Trainer initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9214e121",
   "metadata": {},
   "source": [
    "## Start QAT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1006073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting QAT training...\n",
      "Note: Training with fake quantization may be 10-20% slower than FP32\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bertr\\anaconda3\\envs\\speech_recognition\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad96a4e19bf4e7794186287df401f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2064 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.481, 'learning_rate': 1.9031007751937985e-05, 'epoch': 0.15}\n",
      "{'loss': 0.3566, 'learning_rate': 1.8062015503875972e-05, 'epoch': 0.29}\n",
      "{'loss': 0.2986, 'learning_rate': 1.7093023255813955e-05, 'epoch': 0.44}\n",
      "{'loss': 0.294, 'learning_rate': 1.612403100775194e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3176, 'learning_rate': 1.5155038759689924e-05, 'epoch': 0.73}\n",
      "{'loss': 0.2768, 'learning_rate': 1.4186046511627909e-05, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7024ea9b5c2d41218289a808eb1a1592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29427239298820496, 'eval_accuracy': 0.8896825396825396, 'eval_precision': 0.8913376033580909, 'eval_recall': 0.8896825396825396, 'eval_f1': 0.8898923928032599, 'eval_runtime': 14.9964, 'eval_samples_per_second': 84.02, 'eval_steps_per_second': 5.268, 'epoch': 1.0}\n",
      "{'loss': 0.2689, 'learning_rate': 1.3217054263565892e-05, 'epoch': 1.02}\n",
      "{'loss': 0.1677, 'learning_rate': 1.2248062015503876e-05, 'epoch': 1.16}\n",
      "{'loss': 0.2201, 'learning_rate': 1.1279069767441861e-05, 'epoch': 1.31}\n",
      "{'loss': 0.1577, 'learning_rate': 1.0310077519379846e-05, 'epoch': 1.45}\n",
      "{'loss': 0.1696, 'learning_rate': 9.34108527131783e-06, 'epoch': 1.6}\n",
      "{'loss': 0.1856, 'learning_rate': 8.372093023255815e-06, 'epoch': 1.74}\n",
      "{'loss': 0.1613, 'learning_rate': 7.403100775193799e-06, 'epoch': 1.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b565c3e07b7492083af949ce6a062b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30856966972351074, 'eval_accuracy': 0.8984126984126984, 'eval_precision': 0.8976674612735117, 'eval_recall': 0.8984126984126984, 'eval_f1': 0.8975624784296082, 'eval_runtime': 13.5857, 'eval_samples_per_second': 92.744, 'eval_steps_per_second': 5.815, 'epoch': 2.0}\n",
      "{'loss': 0.1541, 'learning_rate': 6.434108527131784e-06, 'epoch': 2.03}\n",
      "{'loss': 0.1125, 'learning_rate': 5.465116279069767e-06, 'epoch': 2.18}\n",
      "{'loss': 0.0932, 'learning_rate': 4.4961240310077525e-06, 'epoch': 2.33}\n",
      "{'loss': 0.0911, 'learning_rate': 3.527131782945737e-06, 'epoch': 2.47}\n",
      "{'loss': 0.0764, 'learning_rate': 2.558139534883721e-06, 'epoch': 2.62}\n",
      "{'loss': 0.1203, 'learning_rate': 1.5891472868217056e-06, 'epoch': 2.76}\n",
      "{'loss': 0.1035, 'learning_rate': 6.201550387596899e-07, 'epoch': 2.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fae0d46b5641feb1287f1aca245298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3824440538883209, 'eval_accuracy': 0.9007936507936508, 'eval_precision': 0.9002370862048713, 'eval_recall': 0.9007936507936508, 'eval_f1': 0.9004370715467654, 'eval_runtime': 13.3473, 'eval_samples_per_second': 94.401, 'eval_steps_per_second': 5.919, 'epoch': 3.0}\n",
      "{'train_runtime': 1040.6142, 'train_samples_per_second': 31.712, 'train_steps_per_second': 1.983, 'train_loss': 0.2014281939166461, 'epoch': 3.0}\n",
      "\n",
      "======================================================================\n",
      "QAT Training completed!\n",
      "Training loss: 0.2014\n",
      "Training runtime: 1040.61 seconds\n",
      "Training samples/second: 31.71\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting QAT training...\")\n",
    "print(\"Note: Training with fake quantization may be 10-20% slower than FP32\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QAT Training completed!\")\n",
    "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"Training runtime: {train_result.metrics['train_runtime']:.2f} seconds\")\n",
    "print(f\"Training samples/second: {train_result.metrics['train_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb435d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.09858351200819016, max_val=0.10384736210107803)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.042253494262695, max_val=4.5835771560668945)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.10070603340864182, max_val=0.10331607609987259)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.517543792724609, max_val=4.858169078826904)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.08157703280448914, max_val=0.08079499751329422)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7588682174682617, max_val=3.7000069618225098)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.27007362246513367, max_val=0.25236791372299194)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.586731910705566, max_val=3.50299334526062)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.10595253854990005, max_val=0.09485270082950592)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.266414642333984, max_val=6.009731769561768)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.23075592517852783, max_val=0.13342300057411194)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.5224027633667, max_val=4.62345027923584)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.19712497293949127, max_val=0.1760243922472)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.281913757324219, max_val=8.624543190002441)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.1762217879295349, max_val=0.16844648122787476)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.9071221351623535, max_val=7.220548152923584)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.07797542959451675, max_val=0.07943670451641083)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.8847198486328125, max_val=3.7059152126312256)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11572107672691345, max_val=0.11047131568193436)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.495745897293091, max_val=3.3157150745391846)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.10470760613679886, max_val=0.09896843880414963)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.7438249588012695, max_val=11.313392639160156)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.2159060537815094, max_val=0.13175219297409058)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.000868797302246, max_val=4.2412238121032715)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11560390144586563, max_val=0.12230052053928375)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.495567798614502, max_val=5.515828609466553)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11388134956359863, max_val=0.11020638048648834)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.226377487182617, max_val=5.216582298278809)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.09276600927114487, max_val=0.09271663427352905)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.884904384613037, max_val=5.515691757202148)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.1888924539089203, max_val=0.14554716646671295)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.164078712463379, max_val=2.9872703552246094)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.1219409704208374, max_val=0.1534523367881775)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.764443874359131, max_val=6.0138163566589355)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.5633125305175781, max_val=0.312123566865921)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-16.215103149414062, max_val=7.587517261505127)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.17606770992279053, max_val=0.1961582601070404)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.6097540855407715, max_val=7.330377101898193)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.18633601069450378, max_val=0.15496483445167542)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.770823955535889, max_val=7.1233415603637695)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.0956910029053688, max_val=0.10113634169101715)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.608642339706421, max_val=3.5834977626800537)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.09894461184740067, max_val=0.09840722382068634)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.543224811553955, max_val=1.667736291885376)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.12556320428848267, max_val=0.16474704444408417)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.812841892242432, max_val=5.544938087463379)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.5383821725845337, max_val=0.23450109362602234)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.692167282104492, max_val=4.653671741485596)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.13422846794128418, max_val=0.13619357347488403)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.298765182495117, max_val=6.155055522918701)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.1360674798488617, max_val=0.11866634339094162)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.416775226593018, max_val=5.268194198608398)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.08556338399648666, max_val=0.09505802392959595)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4455249309539795, max_val=3.6489417552948)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.12218551337718964, max_val=0.10598738491535187)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6001273393630981, max_val=1.3999192714691162)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.130158931016922, max_val=0.13750001788139343)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.59889554977417, max_val=5.424452781677246)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.5695457458496094, max_val=0.34080517292022705)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.133150100708008, max_val=3.796994686126709)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.18178799748420715, max_val=0.1902071237564087)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.275776863098145, max_val=8.07827377319336)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.16636845469474792, max_val=0.14762641489505768)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.919685363769531, max_val=7.6916823387146)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.09280012547969818, max_val=0.08936398476362228)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4782917499542236, max_val=3.355137586593628)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.12360364198684692, max_val=0.12698344886302948)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.345701694488525, max_val=2.7719597816467285)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.11835863441228867, max_val=0.12488715350627899)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.5361104011535645, max_val=6.331376075744629)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.16964644193649292, max_val=0.13028068840503693)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.9879605770111084, max_val=3.2752649784088135)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.12715153396129608, max_val=0.1342497617006302)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.950101375579834, max_val=6.471982955932617)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11112160980701447, max_val=0.12150336056947708)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.7235822677612305, max_val=6.3200507164001465)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.10318747907876968, max_val=0.09805551916360855)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.060317516326904, max_val=3.857100486755371)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.10980347543954849, max_val=0.10830419510602951)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9520846605300903, max_val=1.9740785360336304)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.11119415611028671, max_val=0.11018471419811249)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.620312690734863, max_val=4.3514814376831055)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.13875548541545868, max_val=0.10733942687511444)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.356445074081421, max_val=2.8833725452423096)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.13306911289691925, max_val=0.12697575986385345)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.032275199890137, max_val=6.263845920562744)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11625862866640091, max_val=0.10785464197397232)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.061384201049805, max_val=5.706316947937012)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.09584753960371017, max_val=0.09983432292938232)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.401089668273926, max_val=3.4613144397735596)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.10436554253101349, max_val=0.11485713720321655)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5973109006881714, max_val=1.600179672241211)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.11413131654262543, max_val=0.12057672441005707)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.858061790466309, max_val=6.090208530426025)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.13576218485832214, max_val=0.09816213697195053)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1412837505340576, max_val=2.0276870727539062)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.12413497269153595, max_val=0.13454733788967133)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.3319621086120605, max_val=6.0652265548706055)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11785168200731277, max_val=0.12434333562850952)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.011072635650635, max_val=5.814993858337402)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.10177519917488098, max_val=0.0959147959947586)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.161008834838867, max_val=4.071659088134766)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.10045045614242554, max_val=0.09491514414548874)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.171250820159912, max_val=1.9559390544891357)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.11120682954788208, max_val=0.11657585948705673)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.817145824432373, max_val=4.697989463806152)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.29868876934051514, max_val=0.11244870722293854)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.2159953117370605, max_val=2.2076189517974854)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.12475968152284622, max_val=0.13530753552913666)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.8411173820495605, max_val=5.988968372344971)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.12338151782751083, max_val=0.11611995100975037)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.544032096862793, max_val=5.280228137969971)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.09911764413118362, max_val=0.10355180501937866)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3592207431793213, max_val=3.3685848712921143)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.10258659720420837, max_val=0.10592585057020187)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9237818717956543, max_val=2.0165367126464844)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.13045309484004974, max_val=0.1331443190574646)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.647176742553711, max_val=6.241636753082275)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.10741186887025833, max_val=0.15191788971424103)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1893200874328613, max_val=2.346022605895996)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.12079821527004242, max_val=0.1205388531088829)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.301079273223877, max_val=5.308184623718262)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11299686878919601, max_val=0.12029729038476944)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.723349094390869, max_val=4.579615116119385)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.0971420630812645, max_val=0.0867418423295021)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.924140691757202, max_val=3.0741453170776367)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.08738238364458084, max_val=0.08207803219556808)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6424599885940552, max_val=1.5797719955444336)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.11190571635961533, max_val=0.12108021974563599)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.231199264526367, max_val=6.159843921661377)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.10879571735858917, max_val=0.11138145625591278)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.2723891735076904, max_val=2.4451894760131836)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11590787023305893, max_val=0.13766512274742126)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.510573863983154, max_val=4.410252571105957)\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.11101006716489792, max_val=0.10919911414384842)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.120971202850342, max_val=4.0154852867126465)\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.08379558473825455, max_val=0.08703308552503586)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.0245625972747803, max_val=2.7513539791107178)\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (weight_fake_quant): MinMaxObserver(min_val=-0.08067131042480469, max_val=0.08044948428869247)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3786755800247192, max_val=1.2963649034500122)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.11413110047578812, max_val=0.10588229447603226)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.364744186401367, max_val=4.49158239364624)\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (weight_fake_quant): MinMaxObserver(min_val=-0.13803115487098694, max_val=0.12785056233406067)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0338337421417236, max_val=2.015028953552246)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(\n",
       "        in_features=768, out_features=768, bias=True\n",
       "        (weight_fake_quant): MinMaxObserver(min_val=-0.08799976855516434, max_val=0.09293200820684433)\n",
       "        (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.397660493850708, max_val=3.464916467666626)\n",
       "      )\n",
       "      (activation): Tanh(\n",
       "        (activation_post_process): FixedQParamsFakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), scale=tensor([0.0078], device='cuda:0'), zero_point=tensor([128], device='cuda:0', dtype=torch.int32), dtype=torch.quint8, quant_min=0, quant_max=255, qscheme=torch.per_tensor_affine\n",
       "          (activation_post_process): FixedQParamsObserver()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(\n",
       "    in_features=768, out_features=3, bias=True\n",
       "    (weight_fake_quant): MinMaxObserver(min_val=-0.06607984006404877, max_val=0.06548072397708893)\n",
       "    (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.9710164070129395, max_val=5.4279327392578125)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_qat.eval()\n",
    "# model_int8 = quantization.convert(model_qat, inplace=False)\n",
    "\n",
    "# print(\"Model converted to INT8\")\n",
    "# print(f\"INT8 model parameters: {model_int8.num_parameters():,}\")\n",
    "# print(\"\\nModel now uses actual INT8 operations instead of fake quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e4780",
   "metadata": {},
   "source": [
    "## Evaluate INT8 (fake-quant) Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417808a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating QAT INT8 model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bertr\\anaconda3\\envs\\speech_recognition\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb1faf87bc24d5a84cde485fa4b206b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QAT INT8 Test Set Results:\n",
      "======================================================================\n",
      "  Accuracy:  0.8760\n",
      "  Precision: 0.8798\n",
      "  Recall:    0.8760\n",
      "  F1 Score:  0.8736\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "model_qat.eval()\n",
    "\n",
    "print(\"Evaluating QAT (fake-quant) model on test set\")\n",
    "test_results = trainer.evaluate(tokenized_dataset['test'])\n",
    "\n",
    "print(\"\\nQAT INT8 Test Set Results:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Accuracy:  {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {test_results['eval_precision']:.4f}\")\n",
    "print(f\"  Recall:    {test_results['eval_recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {test_results['eval_f1']:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53e236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bertr\\anaconda3\\envs\\speech_recognition\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c078bcf6e754548abe0ba90e25c2c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Classification Report:\n",
      "======================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.90      0.89      0.90       208\n",
      "     Neutral       0.92      0.68      0.78        88\n",
      "    Negative       0.84      0.94      0.89       204\n",
      "\n",
      "    accuracy                           0.88       500\n",
      "   macro avg       0.89      0.84      0.86       500\n",
      "weighted avg       0.88      0.88      0.87       500\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "predictions_output = trainer.predict(tokenized_dataset['test'])\n",
    "y_pred = predictions_output.predictions.argmax(-1)\n",
    "y_true = predictions_output.label_ids\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = ['Positive', 'Neutral', 'Negative']\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=label_names, \n",
    "            yticklabels=label_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=12)\n",
    "plt.ylabel(\"True Labels\", fontsize=12)\n",
    "plt.title(\"Confusion Matrix - 3-Label Classification\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_true, y_pred, target_names=label_names))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beaeb76",
   "metadata": {},
   "source": [
    "## Save QAT INT8 (Fake Quant) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f233b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT INT8 model saved to: ./models/indobert-smsa-qat-int8\n",
      "\n",
      "To load the model later:\n",
      "  model = AutoModelForSequenceClassification.from_pretrained('indobenchmark/indobert-base-p2', num_labels=3)\n",
      "  model.load_state_dict(torch.load('./models/indobert-smsa-qat-int8/model_int8.pth'))\n",
      "  tokenizer = AutoTokenizer.from_pretrained('./models/indobert-smsa-qat-int8')\n"
     ]
    }
   ],
   "source": [
    "save_path_qat = \"./models/indobert-smsa-qat-int8\"\n",
    "os.makedirs(save_path_qat, exist_ok=True)\n",
    "\n",
    "model_qat.save_pretrained(save_path_qat)\n",
    "tokenizer.save_pretrained(save_path_qat)\n",
    "\n",
    "print(f\"QAT INT8 (Fake Quant) model saved to: {save_path_qat}\")\n",
    "print(\"\\nTo load the model later:\")\n",
    "print(f\"  model = AutoModelForSequenceClassification.from_pretrained('{save_path_qat}')\")\n",
    "print(f\"  tokenizer = AutoTokenizer.from_pretrained('{save_path_qat}')\")\n",
    "print(f\"\\nModel configuration:\")\n",
    "print(f\"  - num_labels: 3\")\n",
    "print(f\"  - label mapping: {label2id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa4372",
   "metadata": {},
   "source": [
    "## Model Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5eb0e5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size Comparison:\n",
      "======================================================================\n",
      "QAT INT8 model: 230.16 MB\n",
      "Expected FP32 size: ~920.63 MB\n",
      "Size reduction: ~75.0%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "int8_size = os.path.getsize(f\"{save_path_qat}/model_int8.pth\") / (1024 * 1024)\n",
    "\n",
    "print(\"Model Size Comparison:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"QAT INT8 model: {int8_size:.2f} MB\")\n",
    "print(f\"Expected FP32 size: ~{int8_size * 4:.2f} MB\")\n",
    "print(f\"Size reduction: ~{(1 - int8_size / (int8_size * 4)) * 100:.1f}%\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
