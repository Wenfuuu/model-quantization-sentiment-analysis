# PTQ VS QAT
Source Paper : [Optimizing Large Language Models through
Quantization: A Comparative Analysis of PTQ and
QAT Techniques](https://arxiv.org/pdf/2411.06084)

## PTQ 
* Quantize pas model udah selesai di train (pre-train)
* Model udah di train ama FP32, diconvert ke low precision
* Tidak ada retraining

QAT